{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_Switch_v2_Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7quwWZTJlwfV",
        "colab_type": "text"
      },
      "source": [
        "# DQN Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAePzQjrcriF",
        "colab_type": "text"
      },
      "source": [
        "### Environment Example\n",
        "#### Switch2-v0\n",
        "![Switch-2](https://raw.githubusercontent.com/koulanurag/ma-gym/master/static/gif/Switch2-v0.gif)\n",
        "#### Switch4-v0\n",
        "![Switch-4](https://raw.githubusercontent.com/koulanurag/ma-gym/master/static/gif/Switch4-v0.gif)\n",
        "\n",
        "`Switch-n` is a grid world environment having `n agents` where each agent wants to move their corresponding home location (marked in boxes outlined in same colors).\n",
        "Each agent receives only it's local position coordinates. The challenging part of the game is to pass through the narrow corridor through which only one agent can pass at a time. They need to coordinate to not block the pathway for the other. A reward of +5 is given to each agent for reaching their home cell. The episode ends when both agents has reached their home state or for a maximum of 100 steps in environment.\n",
        "\n",
        "Action Space: `0: Down, 1: Left, 2: Up , 3: Right, 4: Noop`\n",
        "\n",
        "Agent Observation : `Agent Coordinate + Steps in env.`\n",
        "\n",
        "Best Score: `NA`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bRNAhv1QMC1",
        "colab_type": "text"
      },
      "source": [
        "### Download Requirements and Set the Environment\n",
        "The following command will download the required scripts and set up the environment. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0MTkFoNkLi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/ma-gym  \n",
        "!git clone https://github.com/koulanurag/ma-gym.git \n",
        "%cd /content/ma-gym \n",
        "!pip install -q -e . \n",
        "!apt-get install -y xvfb python-opengl x11-utils > /dev/null 2>&1\n",
        "!pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install x11-utils\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install -U gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sYf6AK2d6kK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import gym\n",
        "import ma_gym\n",
        "from ma_gym.wrappers import Monitor\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOzRdQAOu7n_",
        "colab_type": "text"
      },
      "source": [
        "#### Example of playing Switch2-v0 Using Random Policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXMuXU52pznF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = wrap_env(gym.make(\"Switch2-v0\")) # Use \"Switch4-v0\" for the Switch-4 game\n",
        "done_n = [False for _ in range(env.n_agents)]\n",
        "ep_reward = 0\n",
        "\n",
        "obs_n = env.reset()\n",
        "while not all(done_n):\n",
        "    obs_n, reward_n, done_n, info = env.step(env.action_space.sample())\n",
        "    ep_reward += sum(reward_n)\n",
        "    env.render()\n",
        "env.close()\n",
        "# To improve the training efficiency, render() is not necessary during the training.\n",
        "# We provide the render and video code here just want to demonstrate how to debugging and analysis.\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHChldNnoWZ4",
        "colab_type": "text"
      },
      "source": [
        "Credit: Code above (Installation and random example) were written by Teaching Assistants from UCL's Multi Agent Artifical Intelligence course. All code below was written by me (Raymond Danks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22rC-6i4YztB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Requirements**\n",
        "* TensorFlow 2.0+ or PyTorch 1.4+ are recommended.\n",
        "*   Algorithm is Multi-Agent, i.e., policy input is the observation/ state for each corresponding agent, not for all agents.\n",
        "\n",
        "Training, Plotting, Testing and Explanation Included.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVQxsW-I3hgG",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFYBKQ8Y3gpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(3517174048)\n",
        "import numpy as np\n",
        "st0 = np.random.get_state()\n",
        "#print(\"current seed?\",st0[0][1])\n",
        "import random\n",
        "random.seed(111)\n",
        "\n",
        "#The below is to stick the TensorFlow version, as concurrent updates can mess it up\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.optimizers import Adam\n",
        "from keras import optimizers\n",
        "from collections import deque\n",
        "from keras.layers import Activation, Dense\n",
        "from collections import deque\n",
        "from copy import deepcopy\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64dJu3WwuBwu",
        "colab_type": "text"
      },
      "source": [
        "#### Code for Playing Switch2-v0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nQj9g0N6CrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_Switch_v2:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.env = wrap_env(gym.make(\"Switch2-v0\"))\n",
        "    self.discount_rate = 0.9\n",
        "    self.batch_size = 32\n",
        "    self.training_episodes = 10000\n",
        "    self.max_timesteps = 50 #Already defined by gym\n",
        "    self.update_frequency = 32 #how often the networks are fitted\n",
        "    self.epsilon_max = 1 #what epsilon starts at (before annealing)\n",
        "    self.epsilon_projection = -0.2 #for linear interpolation\n",
        "    self.epsilon_min = 0.3 #makes sure epsilon does not go below this value\n",
        "    self.max_buffer_size = 100000\n",
        "    self.exploration_episodes = 0 #no training in exploration\n",
        "    self.testing_episodes = 1000 \n",
        "    self.test_epsilon = 0 #some papers claim that a ~5% randomness during testing is beneficial\n",
        "\n",
        "  def _Create_Model(self): # _ = private method.\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, input_dim=3, activation=\"relu\")) # coordinates AND timestep (early and late game strats are different)\n",
        "    model.add(Dense(5, activation=\"linear\")) #Outputs = amount of actions\n",
        "    model.compile(loss='mse',optimizer=\"Adam\") \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "  def _Update_Q_Policy(self,model,replay_batch):\n",
        "    #This function is to update the Q learning ANN model and hence update the Q policy\n",
        "\n",
        "    #The first step is to randomly sample some parts of the data batch:\n",
        "    #Our buffer has a large amount of moves, \n",
        "    #however our asynchronous databatch will just be a randomly chosen batch of these:\n",
        "    independent_batch = []\n",
        "    for i in range(self.batch_size): \n",
        "      random_batch_index = random.randint(0, len(replay_batch)-1) #select random row of the batch\n",
        "      random_batch = replay_batch[random_batch_index]\n",
        "      if i == 0:\n",
        "        independent_batch_messy = random_batch\n",
        "      else:\n",
        "        independent_batch_messy = np.vstack((independent_batch_messy,random_batch))\n",
        "    #Now we have a random batch of the appropriate size.\n",
        "\n",
        "    #columns of the batch go: state,action,new_state,reward,done, timestep\n",
        "\n",
        "    #reformat matrix batch first\n",
        "    independent_batch = np.zeros((self.batch_size,8))\n",
        "    for i in range(len(independent_batch_messy)):\n",
        "      first_coord_x = independent_batch_messy[i,0][0]\n",
        "      first_coord_y = independent_batch_messy[i,0][1]\n",
        "      action_int = independent_batch_messy[i,1]\n",
        "      second_coord_x = independent_batch_messy[i,2][0][0]\n",
        "      second_coord_y = independent_batch_messy[i,2][0][1]\n",
        "      reward_int = independent_batch_messy[i,2][1]\n",
        "      done_int = independent_batch_messy[i,2][2]\n",
        "      timestep_int = independent_batch_messy[i,2][3]\n",
        "\n",
        "      independent_batch[i,0] = first_coord_x \n",
        "      independent_batch[i,1] = first_coord_y\n",
        "      independent_batch[i,2] = action_int\n",
        "      independent_batch[i,3] = second_coord_x\n",
        "      independent_batch[i,4] = second_coord_y\n",
        "      independent_batch[i,5] = reward_int\n",
        "      independent_batch[i,6] = done_int\n",
        "      independent_batch[i,7] = timestep_int\n",
        "    #Batch is now fully formatted\n",
        "\n",
        "    #Firstly, we must gather  all of the current states:\n",
        "\n",
        "    #convert to batch size x 2 matrix for Keras\n",
        "    states = np.zeros((self.batch_size,3)) \n",
        "    for i in range(self.batch_size):\n",
        "      states[i,0] = independent_batch[i][0]\n",
        "      states[i,1] = independent_batch[i][1]\n",
        "      states[i,2] = independent_batch[i][7]\n",
        "    predicted_current_Q = model.predict(states) # this will output the Q values for all possible actions\n",
        "    \n",
        "    #now get the future states:\n",
        "    future_states = np.zeros((self.batch_size,3))\n",
        "    for i in range(self.batch_size):\n",
        "      future_states[i,0] = independent_batch[i,3]\n",
        "      future_states[i,1] = independent_batch[i,4]\n",
        "      future_states[i,2] = independent_batch[i,7]\n",
        "\n",
        "    predicted_future_Q = model.predict(future_states)\n",
        "\n",
        "    #Now we must define \"target\"; this is done slightly in our previous Q Learning system:\n",
        "    targets = []\n",
        "    for j in range(self.batch_size):\n",
        "      done = independent_batch[j,6]\n",
        "      reward = independent_batch[j,5]\n",
        "      if done:\n",
        "        target = reward\n",
        "      else:\n",
        "        V = np.max(predicted_future_Q[j])\n",
        "        target = reward+self.discount_rate*V\n",
        "\n",
        "      action_taken = independent_batch[j,2]\n",
        "\n",
        "      updated_Q_row = predicted_current_Q[j,:] #This is a row of the 5 Q values\n",
        "\n",
        "      updated_Q_row[int(action_taken)] = target #convert float -> int\n",
        "\n",
        "      if j == 0:\n",
        "        targets = target\n",
        "        updated_Q = updated_Q_row\n",
        "      else:\n",
        "        targets = np.vstack((targets,target))\n",
        "        updated_Q = np.vstack((updated_Q,updated_Q_row))\n",
        "      \n",
        "    #Above is updating our Q value with the new \"ideal\" values, which create the Y part for our fitting\n",
        "    #In the Keras notation, the above \"targets\" would be our y values\n",
        "    #Our current values are our X values, which are our current Q values!\n",
        "    #Assuming the network has done this all as one matrix!\n",
        "\n",
        "\n",
        "    X_model = np.zeros((self.batch_size,3)) \n",
        "    X_model[:,0] = independent_batch[:,0]\n",
        "    X_model[:,1] = independent_batch[:,1]\n",
        "    X_model[:,2] = independent_batch[:,7]\n",
        "\n",
        "    #This class is from the Keras website and allows for the loss to be recorded easily\n",
        "    class LossHistory(keras.callbacks.Callback): \n",
        "      def on_train_begin(self, logs={}):\n",
        "          self.losses = []\n",
        "\n",
        "      def on_batch_end(self, batch, logs={}):\n",
        "          self.losses.append(logs.get('loss'))\n",
        "\n",
        "    history = LossHistory()\n",
        "\n",
        "    history = model.fit(X_model,updated_Q, verbose = 0,batch_size = self.batch_size,epochs=200)\n",
        "    mean_loss = np.mean(history.history['loss'])\n",
        "    \n",
        "    return mean_loss \n",
        "    #loss shows how well the network is fit to current policy, not how good policy is.\n",
        "\n",
        "  #assigns the coordinates from the observation to individual agents and attaches the time step.\n",
        "  def _Observation_Conversion(self,observation,timestep): \n",
        "    observation_list_1 = observation[0]\n",
        "    observation_list_2 = observation[1]\n",
        "    \n",
        "    agent_1_x = observation_list_1[0]\n",
        "    agent_1_y = observation_list_1[1]\n",
        "    observation_agent_1 = np.zeros((1,3))\n",
        "    observation_agent_1[0,0] = agent_1_x\n",
        "    observation_agent_1[0,1] = agent_1_y\n",
        "    observation_agent_1[0,2] = timestep\n",
        "\n",
        "    agent_2_x = observation_list_2[0]\n",
        "    agent_2_y = observation_list_2[1]\n",
        "    observation_agent_2 = np.zeros((1,3))\n",
        "    observation_agent_2[0,0] = agent_2_x\n",
        "    observation_agent_2[0,1] = agent_2_y\n",
        "    observation_agent_2[0,2] = timestep\n",
        "    \n",
        "    return observation_agent_1, observation_agent_2\n",
        "\n",
        "\n",
        "  def DQN_Train(self):\n",
        "    env = self.env\n",
        "    done = [False for _ in range(env.n_agents)] #Instantiation of the \"done\" vector.\n",
        "    #above is a 1x2 array with boolean values, for each agent.\n",
        "\n",
        "    #recreate the models for each agent.\n",
        "    model_agent_1 = self._Create_Model()\n",
        "    model_agent_2 = self._Create_Model()\n",
        "\n",
        "\n",
        "    #Replay memory rows: state; action; new_state; reward; done; timestep\n",
        "    timesteps_required = [] #Should eventually be the same size as the maximum number of episodes\n",
        "    type_of_episode = [] #whether max iterations or convergence was reached\n",
        "    total_episode_rewards = []\n",
        "\n",
        "\n",
        "    buffer_switch = 0 #to keep track of when to instantiate the buffer\n",
        "    buffer_counter = 0 #when to activate the fit command - all timesteps together\n",
        "\n",
        "    #instantiate buffers\n",
        "    # replay_memory_agent_1 = deque(maxlen = self.max_buffer_size)\n",
        "    # replay_memory_agent_2 = deque(maxlen = self.max_buffer_size)\n",
        "\n",
        "    amount_of_episodes_maxed_out = 0 #instantiations\n",
        "    amount_of_episodes_completed = 0\n",
        "    all_episodic_rewards = []\n",
        "    buffer_row = 0 #start at zero\n",
        "\n",
        "    total_mean_loss_agent_1 = []\n",
        "    total_mean_loss_agent_2 = []\n",
        "    Episodes_Fitted = [] #for plotting loss\n",
        "\n",
        "    for episodes in range(self.training_episodes):\n",
        "      ep_reward = 0\n",
        "      observation = env.reset() #creates an initial observation\n",
        "      timestep = 0 #reinstantiation before each episode\n",
        "\n",
        "      if episodes < self.exploration_episodes:\n",
        "        epsilon = 1.1 \n",
        "      else:\n",
        "        #Now anneal epsilon until the end of the system\n",
        "        max_ep = self.training_episodes-self.exploration_episodes\n",
        "        ep = episodes-self.exploration_episodes\n",
        "        epsilon = ((max_ep-ep)/(max_ep))*(self.epsilon_max-self.epsilon_projection)+self.epsilon_projection #Linearly anneal epsilon\n",
        "        epsilon = np.max([self.epsilon_min,epsilon])\n",
        "      if episodes % 500 == 0:\n",
        "          print(\"episode \", episodes, \"out of \", self.training_episodes, \"complete.\")\n",
        "          print(\"Epsilon: \",epsilon)\n",
        "          print(\"amount of episodes maxed out: \", amount_of_episodes_maxed_out, \"out of \", episodes)\n",
        "          print(\"amount of episodes completed: \", amount_of_episodes_completed, \"out of \", episodes)\n",
        "      total_episodic_reward = 0\n",
        "      \n",
        "\n",
        "      while (1):  #exit criterion below\n",
        "        buffer_counter+=1 #overall amount of timesteps, across all episodes\n",
        "        timestep += 1 #progress timestep for each action\n",
        "        observation_agent_1, observation_agent_2 = self._Observation_Conversion(observation,timestep)\n",
        "\n",
        "        #Action for each agent MUST be determined by two individual networks,\n",
        "        #since they can't know each other's state (Multi-Agent)\n",
        "\n",
        "        #Defining the current Action\n",
        "        if  random.random() < epsilon: #random chance of random action based on epsilon\n",
        "            action = env.action_space.sample()  #random action\n",
        "        else:\n",
        "            possible_Q_values_agent_1 = model_agent_1.predict(observation_agent_1)\n",
        "            action_agent_1 = np.argmax(possible_Q_values_agent_1) # Pick the current policy's best action\n",
        "\n",
        "            possible_Q_values_agent_2 = model_agent_2.predict(observation_agent_2)\n",
        "            action_agent_2 = np.argmax(possible_Q_values_agent_2)\n",
        "\n",
        "            action = [action_agent_1,action_agent_2]\n",
        "\n",
        "        replay_memory_current_action_agent_1 = [observation[0],action[0]]\n",
        "        replay_memory_current_action_agent_2 = [observation[1],action[1]]\n",
        "\n",
        "        observation, reward, done, info = env.step(action)\n",
        "      \n",
        "        replay_memory_current_action_agent_1.append([observation[0],reward[0],done[0],timestep]) #observation is now next state\n",
        "        replay_memory_current_action_agent_2.append([observation[1],reward[1],done[1],timestep])\n",
        "\n",
        "        if buffer_counter == 1: #instantiation of buffers\n",
        "          replay_memory_agent_1 = replay_memory_current_action_agent_1\n",
        "          replay_memory_agent_2 = replay_memory_current_action_agent_2\n",
        "        elif len(replay_memory_agent_1) >= max_buffer_size: #If buffer is full then progressively replace older observations\n",
        "          replay_memory_agent_1[buffer_row,:] = replay_memory_current_action_agent_1\n",
        "          replay_memory_agent_2[buffer_row,:] = replay_memory_current_action_agent_2\n",
        "          if buffer_row == max_buffer_size-1: #-1 because it starts at 0\n",
        "            buffer_row = 0\n",
        "          else:\n",
        "            buffer_row += 1\n",
        "\n",
        "\n",
        "        else: #Building the replay memory\n",
        "          replay_memory_agent_1 = np.vstack((replay_memory_agent_1,replay_memory_current_action_agent_1))\n",
        "          replay_memory_agent_2 = np.vstack((replay_memory_agent_2,replay_memory_current_action_agent_2))\n",
        "\n",
        "        #Begin the fitting of the system - the data should be non-temporal and each row contains all info we need.\n",
        "        if buffer_counter % self.update_frequency == 0 and episodes >= self.exploration_episodes: \n",
        "          mean_loss_agent_1 = self._Update_Q_Policy(model_agent_1,replay_memory_agent_1)\n",
        "          mean_loss_agent_2 = self._Update_Q_Policy(model_agent_2,replay_memory_agent_2)\n",
        "          total_mean_loss_agent_1 = np.append(total_mean_loss_agent_1,mean_loss_agent_1)\n",
        "          total_mean_loss_agent_2 = np.append(total_mean_loss_agent_2,mean_loss_agent_2)\n",
        "          Episodes_Fitted = np.append(Episodes_Fitted,episodes)\n",
        "\n",
        "        ep_reward += sum(reward) #This is the reward for each timestep.\n",
        "        total_episodic_reward += ep_reward\n",
        "\n",
        "        if timestep >= self.max_timesteps: #do >= to avoid bugs - robustness!\n",
        "          timesteps_required = np.append(timesteps_required,timestep)\n",
        "          type_of_episode = np.append(type_of_episode,\"Max_Reached\")\n",
        "          total_episode_rewards = np.append(total_episode_rewards,ep_reward)\n",
        "          amount_of_episodes_maxed_out+=1\n",
        "          all_episodic_rewards = np.append(all_episodic_rewards,total_episodic_reward)\n",
        "          break\n",
        "        elif all(done): #stops each episode once the agents have completed the course\n",
        "          timesteps_required = np.append(timesteps_required,timestep)\n",
        "          type_of_episode = np.append(type_of_episode,\"Completed_Game\")\n",
        "          total_episode_rewards = np.append(total_episode_rewards,ep_reward)\n",
        "          amount_of_episodes_completed+=1\n",
        "          all_episodic_rewards = np.append(all_episodic_rewards,total_episodic_reward)\n",
        "          break\n",
        "    env.render() #added in for visualisation\n",
        "    env.close()\n",
        "    print(\"timesteps required: \",timesteps_required)\n",
        "    print(\"timesteps_required size: \",timesteps_required.size)\n",
        "    print(\"type of episodes: \",type_of_episode)\n",
        "    print(\"type of episode size: \",type_of_episode.size)\n",
        "    print(\"all rewards: \",total_episode_rewards)\n",
        "    print(\"all rewards size: \",total_episode_rewards.size)\n",
        "    print(\"amount of episodes maxed out: \", amount_of_episodes_maxed_out, \"out of \", self.training_episodes)\n",
        "    print(\"amount of episodes completed: \", amount_of_episodes_completed, \"out of \", self.training_episodes)\n",
        "    # To improve the training efficiency, render() is not necessary during the training.\n",
        "    # We provide the render and video code here just want to demonstrate how to debugging and analysis.\n",
        "    # show_video()\n",
        "\n",
        "    #now we set these variables for use in plotting:\n",
        "    self.final_rewards = total_episode_rewards\n",
        "    self.final_mean_losses_agent_1 = total_mean_loss_agent_1\n",
        "    self.final_mean_losses_agent_2 = total_mean_loss_agent_2\n",
        "    self.episodes_fitting_occurred = Episodes_Fitted #to make plotting more accurate\n",
        "\n",
        "\n",
        "\n",
        "  def DQN_Plot(self):\n",
        "\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
        "\n",
        "\n",
        "    number_of_episodes = len(all_episodic_rewards)\n",
        "    episode_matrix = np.arange(0,number_of_episodes)\n",
        "\n",
        "    ax1.plot(episode_matrix, self.final_rewards)\n",
        "    ax1.set_title(\"Learning Curve\")\n",
        "    ax1.set_ylabel(\"Episodic Reward (Cumulative for Both Agents)\")\n",
        "    ax1.set_xlabel(\"Episodes\")\n",
        "\n",
        "    ax2.plot(self.episodes_fitting_occurred, self.final_mean_losses_agent_1)\n",
        "    ax2.set_title(\"Loss for Agent 1\")\n",
        "    ax2.set_ylabel(\"Average Loss across epochs\")\n",
        "    ax2.set_xlabel(\"Episodes when Fitting occurred\")\n",
        "\n",
        "\n",
        "    ax3.plot(self.episodes_fitting_occurred, self.final_mean_losses_agent_1)\n",
        "    ax3.set_title(\"Loss for Agent 2\")\n",
        "    ax3.set_ylabel(\"Average Loss across epochs\")\n",
        "    ax3.set_xlabel(\"Episodes when Fitting occurred\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  #This is the same as the training code, except the networks are not updated, hence less comments\n",
        "  def Dqn_Test(self):\n",
        "    env = self.env\n",
        "    timestep = 0 #reinstantiation before each episode too\n",
        "    episodes_maxed_out_test = 0\n",
        "    episodes_completed_test = 0\n",
        "    total_episode_rewards_test = []\n",
        "    type_of_episode_test = []\n",
        "    timesteps_required_test = []\n",
        "\n",
        "    for episodes in range(self.testing_episodes):\n",
        "      timestep = 0\n",
        "      observation = env.reset() \n",
        "      ep_reward = 0\n",
        "      if episodes % 1000 == 0:\n",
        "        print(\"episode \",episodes,\"out of \",self.testing_episodes,\"Completed.\")\n",
        "      while (1):  #exit criterion below\n",
        "          timestep += 1 #progress timestep for each action\n",
        "          observation_agent_1, observation_agent_2 = self._Observation_Conversion(observation,timestep)\n",
        "\n",
        "          if random.random() < self.test_epsilon:\n",
        "            action = env.action_space.sample()\n",
        "          else:\n",
        "            possible_Q_values_agent_1 = model_agent_1.predict(observation_agent_1)\n",
        "            action_agent_1 = np.argmax(possible_Q_values_agent_1)\n",
        "\n",
        "            possible_Q_values_agent_2 = model_agent_2.predict(observation_agent_2)\n",
        "            action_agent_2 = np.argmax(possible_Q_values_agent_2)\n",
        "\n",
        "            action = [action_agent_1,action_agent_2]\n",
        "\n",
        "          observation, reward, done, info = env.step(action)\n",
        "          ep_reward += sum(reward)\n",
        "\n",
        "          if timestep >= self.max_timesteps: \n",
        "            # print(\"timesteps required: \",timestep)\n",
        "            type_of_episode_test = np.append(type_of_episode_test,\"Max_Reached\")\n",
        "            total_episode_rewards_test = np.append(total_episode_rewards_test,ep_reward)\n",
        "            episodes_maxed_out_test += 1\n",
        "            timesteps_required_test = np.append(timesteps_required_test,timestep)\n",
        "            # print(\"done: \",done)\n",
        "            break\n",
        "          elif all(done): #stops each episode once the agents have completed the course\n",
        "            type_of_episode_test = np.append(type_of_episode_test,\"Completed Game\")\n",
        "            total_episode_rewards_test = np.append(total_episode_rewards_test,ep_reward)\n",
        "            episodes_completed_test += 1\n",
        "            timesteps_required_test = np.append(timesteps_required_test,timestep)\n",
        "            break\n",
        "          env.render()\n",
        "\n",
        "    print(\"timesteps required: \",timesteps_required_test)\n",
        "    print(\"timesteps_required size: \",timesteps_required_test.size)\n",
        "    print(\"type of episodes: \",type_of_episode_test)\n",
        "    print(\"type of episode size: \",type_of_episode_test.size)\n",
        "    print(\"all rewards: \",total_episode_rewards_test)\n",
        "    print(\"all rewards size: \",total_episode_rewards_test.size)\n",
        "    print(\"amount of episodes maxed out: \", episodes_maxed_out_test, \"out of \", self.testing_episodes)\n",
        "    print(\"amount of episodes completed: \", episodes_completed_test, \"out of \", self.testing_episodes)\n",
        "\n",
        "    env.close()\n",
        "    # To improve the training efficiency, render() is not necessary during the training.\n",
        "    # We provide the render and video code here just want to demonstrate how to debugging and analysis.\n",
        "    show_video()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iin9WBe4uLY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e1bf29b-7e5a-4150-9cae-478f2d6b79c8"
      },
      "source": [
        "DQN = DQN_Switch_v2()\n",
        "DQN.DQN_Train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode  0 out of  10000 complete.\n",
            "Epsilon:  1.1\n",
            "amount of episodes maxed out:  0 out of  0\n",
            "amount of episodes completed:  0 out of  0\n",
            "episode  500 out of  10000 complete.\n",
            "Epsilon:  1.1\n",
            "amount of episodes maxed out:  498 out of  500\n",
            "amount of episodes completed:  2 out of  500\n",
            "episode  1000 out of  10000 complete.\n",
            "Epsilon:  1.1\n",
            "amount of episodes maxed out:  997 out of  1000\n",
            "amount of episodes completed:  3 out of  1000\n",
            "episode  1500 out of  10000 complete.\n",
            "Epsilon:  1.1\n",
            "amount of episodes maxed out:  1495 out of  1500\n",
            "amount of episodes completed:  5 out of  1500\n",
            "episode  2000 out of  10000 complete.\n",
            "Epsilon:  1.1\n",
            "amount of episodes maxed out:  1991 out of  2000\n",
            "amount of episodes completed:  9 out of  2000\n",
            "episode  2500 out of  10000 complete.\n",
            "Epsilon:  1.0\n",
            "amount of episodes maxed out:  2490 out of  2500\n",
            "amount of episodes completed:  10 out of  2500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "episode  3000 out of  10000 complete.\n",
            "Epsilon:  0.9199999999999999\n",
            "amount of episodes maxed out:  2987 out of  3000\n",
            "amount of episodes completed:  13 out of  3000\n",
            "episode  3500 out of  10000 complete.\n",
            "Epsilon:  0.8400000000000001\n",
            "amount of episodes maxed out:  3469 out of  3500\n",
            "amount of episodes completed:  31 out of  3500\n",
            "episode  4000 out of  10000 complete.\n",
            "Epsilon:  0.76\n",
            "amount of episodes maxed out:  3923 out of  4000\n",
            "amount of episodes completed:  77 out of  4000\n",
            "episode  4500 out of  10000 complete.\n",
            "Epsilon:  0.6799999999999999\n",
            "amount of episodes maxed out:  4370 out of  4500\n",
            "amount of episodes completed:  130 out of  4500\n",
            "episode  5000 out of  10000 complete.\n",
            "Epsilon:  0.5999999999999999\n",
            "amount of episodes maxed out:  4749 out of  5000\n",
            "amount of episodes completed:  251 out of  5000\n",
            "episode  5500 out of  10000 complete.\n",
            "Epsilon:  0.52\n",
            "amount of episodes maxed out:  5066 out of  5500\n",
            "amount of episodes completed:  434 out of  5500\n",
            "episode  6000 out of  10000 complete.\n",
            "Epsilon:  0.44\n",
            "amount of episodes maxed out:  5388 out of  6000\n",
            "amount of episodes completed:  612 out of  6000\n",
            "episode  6500 out of  10000 complete.\n",
            "Epsilon:  0.35999999999999993\n",
            "amount of episodes maxed out:  5692 out of  6500\n",
            "amount of episodes completed:  808 out of  6500\n",
            "episode  7000 out of  10000 complete.\n",
            "Epsilon:  0.3\n",
            "amount of episodes maxed out:  6021 out of  7000\n",
            "amount of episodes completed:  979 out of  7000\n",
            "episode  7500 out of  10000 complete.\n",
            "Epsilon:  0.3\n",
            "amount of episodes maxed out:  6389 out of  7500\n",
            "amount of episodes completed:  1111 out of  7500\n",
            "episode  8000 out of  10000 complete.\n",
            "Epsilon:  0.3\n",
            "amount of episodes maxed out:  6756 out of  8000\n",
            "amount of episodes completed:  1244 out of  8000\n",
            "episode  8500 out of  10000 complete.\n",
            "Epsilon:  0.3\n",
            "amount of episodes maxed out:  7134 out of  8500\n",
            "amount of episodes completed:  1366 out of  8500\n",
            "episode  9000 out of  10000 complete.\n",
            "Epsilon:  0.3\n",
            "amount of episodes maxed out:  7553 out of  9000\n",
            "amount of episodes completed:  1447 out of  9000\n",
            "episode  9500 out of  10000 complete.\n",
            "Epsilon:  0.3\n",
            "amount of episodes maxed out:  7905 out of  9500\n",
            "amount of episodes completed:  1595 out of  9500\n",
            "timesteps required:  [50. 50. 50. ... 30. 50. 32.]\n",
            "timesteps_required size:  10000\n",
            "type of episodes:  ['Max_Reached' 'Max_Reached' 'Max_Reached' ... 'Completed_Game'\n",
            " 'Max_Reached' 'Completed_Game']\n",
            "type of episode size:  10000\n",
            "all rewards:  [-10.  -10.  -10.  ...   4.2 -10.    3.8]\n",
            "all rewards size:  10000\n",
            "amount of episodes maxed out:  8266 out of  10000\n",
            "amount of episodes completed:  1734 out of  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6_h9OFiBuIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DQN.DQN_Test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTZoC30suOe7",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgkfaU2RuRaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "e6396fcf-9e7a-4309-abfc-443b69efb720"
      },
      "source": [
        "DQN.DQN_Plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAFgCAYAAADuCe0ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezZ3R-q4uH7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "35e157ea-f95c-44e1-9a66-dba76b9927db"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAFgCAYAAADuCe0ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd5xcdbnH8c93SzYhCUkgoQYITRCk\nR6UqRSlil3pRAb0qXizYgAgKeEUsiIAovQheOqgISOgQIBASehJKSAIESO+bZOtz/zhnN5NlN3uy\n2dk9O/t9v17z2jn9mdnZfeZXzu+niMDMzCxvyro7ADMzs9Y4QZmZWS45QZmZWS45QZmZWS45QZmZ\nWS45QZmZWS45QZmtBUn9JP1b0iJJt3V3PGalxAnKSoKk6ZI+1Q2XPgLYEFg/Io7srJNK2lJSo6RL\nO+ucGa55gqQn2tnnKElPSVom6dEuCs16KScos7WzBfB6RNSv6YGSKlaz+evAAuBoSVUdDa4I5gMX\nAr/t7kCs9DlBWUmTVCXpQknvpY8Lm/7hSxoq6W5JCyXNlzRGUlm67TRJ70paIuk1SQe1cu5zgF+S\nJJGlkr4pqUzSmZLekjRb0vWSBqX7j5AU6X5vAw+3EbNIEtSZQB3wuRbbD05jWiTpr5Iek/TfBdu/\nIWmypAWSRkvaomBbSDpJ0hvp6/6LEh8GLgP2Sl/LwtZii4gHI+JW4L3svwWzjnGCslJ3BrAnsCuw\nC/Axkn/8AD8BZgDDSKrpfg6EpO2A7wEfjYiBwCHA9JYnjoizgN8At0TEgIi4GjghfRwAbAUMAC5p\ncegngQ+n523NvsBw4GbgVuD4pg2ShgK3A6OA9YHXgL0Ltn8hfR1fTl/XGOCmFuf/LPBRYGfgKOCQ\niJgMnASMTV/L4DZiM+syTlBW6o4DfhURsyNiDnAO8LV0Wx2wMbBFRNRFxJhIBqdsAKqAHSRVRsT0\niHhzDa53QURMjYilJInkmBbVeWdHRHVELG/jHMcD/4mIBcCNwKGSNki3fQaYGBF3ptWKFwMzC449\nCTgvIian238D7FpYigJ+GxELI+Jt4BGS5G2WO05QVuo2Ad4qWH4rXQfwB2AKcL+kqZJOB4iIKcAp\nwNnAbEk3S9qEbFq7XgVJCa3JO20dLKkfcCTwf2ksY4G3gf8qOH/z8WlCnVFwii2Ai9Lqu4UkbUYC\nNi3YpzChLSMp5ZnljhOUlbr3SP5pN9k8XUdELImIn0TEVsDngR83tTVFxI0RsW96bAC/W4vr1QOz\nCtatbgqBLwHrAn+VNFPSTJLk0lTN9z5J9R/Q3F41vOD4d4DvRMTggke/iHgqQ+ye2sByxQnKSkml\npL4FjwqS9pczJQ1L229+CfwdQNJnJW2T/pNfRFK11yhpO0kHpp0pVgDLgcaMMdwE/CjtJj6AlW1U\nWXv5HQ9cA+xEUvW2K7APsIuknYB7gJ0kfTF9fScDGxUcfxkwStKO6WscJClr9/dZwHBJfdraQVK5\npL4kpcKy9H2uzHh+szXiBGWl5F6SZNL0OBv4NTAeeAl4GXguXQewLfAgsBQYC/w1Ih4haX/6LTCX\npDpsA5K2pCyuAW4AHgemkSS472c5UNKmwEHAhRExs+AxAbgPOD4i5pJUAf4emAfskL6+GoCI+AdJ\nae9mSYuBV4DDMsb+MDARmClpbhv7fI3kvb0U2C99fmXG85utEXnCQrOeK+0WPwM4Lk2uZiXDJSiz\nHkbSIZIGp1WQPyfpBPF0N4dl1umcoMx6nr2AN0mqID8HfHE1XdbNeixX8ZmZWS65BGVmZrm0usEq\nu9zQoUNjxIgR3R2GmZl1kQkTJsyNiGGtbctVghoxYgTjx4/v7jDMzKyLSHqrrW2u4jMzs1xygjIz\ns1xygjIzs1xygjIzs1xygjIzs1xygjIzs1xygjIzs1xygjIzs1xygjIzs1xygjIzs1wqqQQ1d2kN\n86truzsMMzPrBCWVoL553bP8+NYXujsMMzPrBCWVoMzMrHQ4QZmZWS45QZmZWS45QZmZWS45QZmZ\nWS45QZmZWS45QZmZWS45QZmZWS6VXIKK6O4IzMysM5RWgpK6OwIzM+skpZWgzMysZDhBmZlZLjlB\nmZlZLjlBmZlZLhU9QUkql/S8pLuLfS0zMysdXVGC+iEwuQuuY2ZmJaSoCUrScOBw4KpiXsfMzEpP\nsUtQFwKnAo1Fvk4z36drZlYaipagJH0WmB0RE9rZ79uSxksaP2fOnLW75lodbWZmeVLMEtQ+wOcl\nTQduBg6U9PeWO0XEFRExMiJGDhs2rIjhmJlZT1K0BBURoyJieESMAI4BHo6IrxbremZmVlp8H5SZ\nmeVSRVdcJCIeBR7timuZmVlpcAnKzMxyyQnKzMxyyQnKzMxyyQnKzMxyqeQSVHjOdzOzklBSCcoz\nvpuZlY6SSlBmZlY6nKDMzCyXnKDMzCyXnKDMzCyXnKDMzCyXnKDMzCyXnKDMzCyXnKDMzCyXnKDM\nzCyXSipBeSAJM7PSUVIJyszMSocTlJmZ5ZITlJmZ5ZITlJmZ5ZITlJmZ5ZITlJmZ5ZITlJmZ5VLJ\nJSjP+G5mVhpKKkHJc76bmZWMkkpQZmZWOpygzMwsl5ygzMwsl5ygzMwsl5ygzMwsl5ygzMwsl5yg\nzMwsl5ygzMwsl0ouQQUeSsLMrBSUVILyOBJmZqWjpBKUmZmVDicoMzPLJScoMzPLJScoMzPLJSco\nMzPLJScoMzPLpTVKUJKGSNq5WMGYmZk1aTdBSXpU0rqS1gOeA66UdEHxQ+sYT/luZlYaspSgBkXE\nYuDLwPUR8XHgU8UNq2M847uZWenIkqAqJG0MHAXcXeR4zMzMgGwJ6lfAaGBKRDwraSvgjeKGZWZm\nvV1FeztExG3AbQXLU4GvFDMoMzOzdhOUpGHAt4ARhftHxDeKF5aZmfV27SYo4F/AGOBBoKG44ZiZ\nmSWyJKh1IuK0okdiZmZWIEsnibslfabokZiZmRVoswQlaQkQJPMA/lxSDVCXLkdErNs1IZqZWW/U\nZoKKiIFdGUhn8UgSZmalIctQR1+SNKhgebCkL2Y4rq+kcZJelDRR0jlrG2y71/Sk72ZmJSNLG9RZ\nEbGoaSEiFgJnZTiuBjgwInYBdgUOlbRnx8I0M7PeJksvvtaSWJYbfANYmi5Wpg9XwJmZWSZZSlDj\nJV0gaev0cQEwIcvJJZVLegGYDTwQEc+0ss+3JY2XNH7OnDlrFr2ZmZWsLAnq+0AtcEv6qAFOznLy\niGiIiF2B4cDHJH2klX2uiIiRETFy2LBh2SM3M7OSlqWqrho4XdLAZDGWtndMK+dYKOkR4FDglTUP\n08zMepssvfh2kvQ8SWKZKGlCayWhVo4bJmlw+rwf8Gng1bUN2MzMeocsnSQuB34cEY8ASNofuALY\nu53jNgb+JqmcJBHeGhGeT8rMzDLJkqD6NyUngIh4VFL/9g6KiJeA3dYmuI4IdxQ0MysJWRLUVEm/\nAG5Il78KTC1eSGvB9+mamZWMLL34vgEMA+5MH8PSdWZmZkWTpRffAuAH6XBHjRGxpPhhmZlZb5el\nF99HJb0MvAi8nI6tt0fxQzMzs94sSxvU1cD/RMQYAEn7AtcCOxczMDMz692ytEE1NCUngIh4Aqgv\nXkhmZmbZSlCPSbocuIlksNejgUcl7Q4QEc8VMT4zM+ulsiSoXdKfLafY2I0kYR3YqRGZmZmRrRff\nAV0RiJmZWaEsvfg2lHS1pP+kyztI+mbxQ+sYT/luZlYasnSSuA4YDWySLr8OnFKsgNaGB5IwMysd\nWRLU0Ii4FWgEiIh6oKGoUZmZWa+XJUFVS1qfdLp2SXsCi4oalZmZ9XpZevH9GLgL2FrSkyRj8R1R\n1KjMzKzXy9KL7zlJnwS2I2nmeS0i6ooemZmZ9WpZSlBN7U4TixyLmZlZsyxtUGZmZl3OCcrMzHIp\ny426+zRN8S7pq5IukLRF8UPrGN+na2ZWGrKUoC4FlknaBfgJ8CZwfVGj6iD5Tl0zs5KRJUHVR0QA\nXwAuiYi/AAOLG5aZmfV2WXrxLZE0Cvgq8AlJZUBlccMyM7PeLksJ6migBvhmRMwEhgN/KGpUZmbW\n62UqQQEXRUSDpA8B25NMXmhmZlY0WUpQjwNVkjYF7ge+RjLCuZmZWdFkSVCKiGXAl4G/RsSRwEeK\nG5aZmfV2mRKUpL2A44B71uA4MzOzDsuSaE4BRgH/iIiJkrYCHiluWGZm1ttlGc38MeAxSQMkDYiI\nqcAPih9aB3koCTOzkpBlqKOdJD1PMpr5JEkTJO1Y/NDWnDzpu5lZychSxXc58OOI2CIiNicZ7ujK\n4oZlZma9XZYE1T8imtucIuJRoH/RIjIzMyPbjbpTJf0CuCFd/iowtXghmZmZZStBfQMYBtwJ3AEM\nTdeZmZkVzWpLUJLKgTsj4oAuisfMzAxopwQVEQ1Ao6RBXRSPmZkZkK0NainwsqQHgOqmlRGR33uh\nzMysx8uSoO5MHz1C+E5dM7OSkCVB3Q6sSKv7mtqlqooaVQd5ynczs9KRpRffQ0C/guV+wIPFCcfM\nzCyRJUH1jYilTQvp83WKF5KZmVm2BFUtafemBUl7AMuLF5KZmVm2NqhTgNskvQcI2Ag4uqhRmZlZ\nr5dluo1nJW0PbJeuei0i6ooblpmZ9XZZSlCQJKcdgL7A7pKIiOuLF5aZmfV27SYoSWcB+5MkqHuB\nw4AnACcoMzMrmiydJI4ADgJmRsSJwC6Ahz4yM7OiypKglkdEI1AvaV1gNrBZccPquPBAEmZmJSFL\nG9R4SYNJZtGdQDI239iiRtVBHknCzKx0ZOnF9z/p08sk3QesGxEvFTcsMzPr7bL24gMgIqYXKQ4z\nM7NVZGmDMjMz63JOUGZmlkvtJihJW0uqSp/vL+kHaaeJ9o7bTNIjkiZJmijph50RsJmZ9Q5ZSlB3\nAA2StgGuIOlifmOG4+qBn0TEDsCewMmSduhwpGZm1qtkSVCNEVEPfAn4c0T8DNi4vYMi4v2IeC59\nvgSYDGy6NsGamVnvkSVB1Uk6FjgeuDtdV7kmF5E0AtgNeKaVbd+WNF7S+Dlz5qzJaVvl+3TNzEpD\nlgR1IrAXcG5ETJO0JXBD1gtIGkBSTXhKRCxuuT0iroiIkRExctiwYVlP2/q18J26ZmalIsuNupOA\nHwBIGgIMjIjfZTm5pEqS5PR/EXHn2gRqZma9S5ZefI9KWlfSesBzwJWSLshwnICrgckR0e7+ZmZm\nhbJU8Q1Kq+a+DFwfER8HPpXhuH2ArwEHSnohfXxmLWI1M7NeJMtQRxWSNgaOAs7IeuKIeALcKGRm\nZh2TpQT1K2A08GY6/ftWwBvFDcvMzHq7LJ0kbgNuK1ieCnylmEGZmZll6SQxXNI/JM1OH3dIGt4V\nwZmZWe+VpYrvWuAuYJP08e90nZmZWdFkSVDDIuLaiKhPH9cBa3dHbRGF53w3MysJWRLUPElflVSe\nPr4KzCt2YB3hKd/NzEpHlgT1DZIu5jOB94EjgBOKGJOZmVmmXnxvAZ8vXCfpfOCnxQrKzMysozPq\nHtWpUZiZmbXQ0QTl1h4zMyuqNqv40sFhW92EE5SZmRXZ6tqgJpDM/9daMqotTjhmZmaJNhNURGzZ\nlYGYmZkV6mgbVG75Nl0zs9JQcgnKzMxKgxOUmZnlUqYEJWlfSSemz4dJcvuUmZkVVZbpNs4CTgNG\npasqgb8XMygzM7MsJagvkQx1VA0QEe8BA4sZlJmZWZYEVRvJHBYBIKl/cUMyMzPLlqBulXQ5MFjS\nt4AHgSuLG5aZmfV2WUYzP1/Sp4HFwHbALyPigaJHZmZmvVq7CQogTUhOSmZm1mXaTVCSlvDBARoW\nAeOBn0TE1GIE1lGe8d3MrDRkKUFdCMwAbiQZOPYYYGvgOeAaYP9iBbem5DnfzcxKRpZOEp+PiMsj\nYklELI6IK4BDIuIWYEiR4zMzs14qS4JaJukoSWXp4yhgRbrNFWpmZlYUWRLUccDXgNnArPT5VyX1\nA75XxNjMzKwXy9LNfCrwuTY2P9G54ZiZmSWy9OLrC3wT2BHo27Q+Ir5RxLjMzKyXy1LFdwOwEXAI\n8BgwHFhSzKDMzMyyJKhtIuIXQHVE/A04HPh4ccMyM7PeLkuCqkt/LpT0EWAQsEHxQlo77lZoZlYa\nstyoe4WkIcCZwF3AAOAXRY2qg3ybrplZ6VhtgpJUBiyOiAXA48BWXRKVmZn1equt4ouIRuDULorF\nzMysWZY2qAcl/VTSZpLWa3oUPTIzM+vVsrRBHZ3+PLlgXeDqPjMzK6IsI0ls2RWBmJmZFWq3ik/S\nOpLOlHRFurytpM8WPzQzM+vNsrRBXQvUAnuny+8Cvy5aRGZmZmRLUFtHxO9Jb9iNiGX4liMzMyuy\nLAmqNp1aIwAkbQ3UFDWqteE5383MSkKWXnxnA/cBm0n6P2Af4IQixtRhnvHdzKx0ZOnFd7+kCcCe\nJFV7P4yIuUWPzMzMerUs80H9G7gRuCsiqosfkpmZWbY2qPOB/YBJkm6XdEQ6iaGZmVnRZKniewx4\nTFI5cCDwLeAaYN0ix2ZmZr1Ylk4SpL34Pkcy7NHuwN+KGZSZmVmWNqhbgY+R9OS7BHgsHeXczMys\naLKUoK4Gjo2IBgBJ+0o6NiJObuc4MzOzDsvSBjVa0m6SjgWOAqYBdxY9MjMz69XaTFCSPgQcmz7m\nArcAiogDuii2DvE4EmZmpWF13cxfJem199mI2Dci/gw0ZD2xpGskzZb0ytoGmfmaXXUhMzMrutUl\nqC8D7wOPSLpS0kGsWQ64Djh0LWIzM7NerM0EFRH/jIhjgO2BR4BTgA0kXSrp4PZOHBGPA/M7LVIz\nM+tV2h1JIiKqI+LGiPgcMBx4HjitswKQ9G1J4yWNnzNnTmed1szMergsQx01i4gFEXFFRBzUWQGk\n5xsZESOHDRvWWac1M7Mebo0SlJmZWVdxgiqShsagpj5zp0czM2uhaAlK0k3AWGA7STMkfbNY18qj\nE64dx3Zn3tfdYZiZ9ViZBovtiIg4tljnXv11u+OqHzTmDc/paGa2Nkqqik+e893MrGSUVIIyM7PS\n4QRlZma55ARlZma55ARlZma55ARlZma55ARlZma55ARlZma55ARlZma5VHIJKjzpu5lZSSipBOVx\nJMzMSkdJJSgzMysdTlBmZpZLRRvNvDs89Ors7g7BzMw6iUtQZmaWS05QZmaWS05QZmaWS05QZmaW\nS05QZmaWS05QRVZb39jdIZiZ9UhOUEW2cHltd4dgZtYjOUEVm4cGNDPrECeoInN+MjPrGCeoIgtn\nKDOzDnGCKjJP/2Fm1jFOUEXmEpSZWcc4QRWZ85OZWcc4QRVZuAhlZtYhTlBF5vxkZtYxTlBmZpZL\nTlBF1tDoIpSZWUeUZILKU7tPY45iMTPrSUo0QXV3BCu5AGVm1jGlmaC6O4ACeSrNmZn1JKWZoHKU\nFBpyFIuZWU9SmgmquwMocOiFY3h34fLuDsPMrMcpzQSVpwwFvDxjUXeHYGbW45RkgsobqbsjMDPr\neUoyQeVtBHHnJzOzNVeaCSpf+cnMzDqgJBNU3sh1fGZma6ykEtTumw8G8leCcnoyM1tzJZWgDt5x\nIyCHbVBrmKFem7mEEaffw8OvzipOQGZmPUBJJaimPJC7EtQaJqjn3l4AwP0TO56gjrliLCN//WCH\njzcz624V3R1AZ1pW2wDkb4BWrUEl38T3FrFwWd1aX/PpqfPX+hxmZt2ppEpQFz30BgAPTZ6d+ZiI\n4PYJM1ieJrfO8IGhltagBHX4xU/wu/te7bRYeosVdQ3cMHZ6roa5MrO1U1IJqsmKuuzJZuyb8/jp\nbS/y4V/ex/uLOmdIouoWye6ld1YdSWLxijqW1dZ3yrUscf7o1/jFvyZy3yszi3L+F99ZyFvzqoty\n7rx4b+Fypsxe2t1h9Cp1DY3MWryiu8PIrZJMUGUSNfUN1DU0trvvsoJkcs0T09rc7805S3l73jKu\nfmIad734Xpv7/e/dk/jIWaNXWfenB19fZXnns+9nv9890m5slt38ZbVA8uXgOzeM57//9izLaxt4\nc07n/MP9wl+e5JN/eLRTzpUXD0yaxfS5K5Pu3r99mE9d8Fg3RrTSuGnzeeXdjg0R1tgYzF7SM/7p\n//zOl/n4bx5iaU09Z/3rFSerFkqqDaqZYLsz76NPRRlbDe3P1hsMYOuh/dlt8yEcsP0Gq+xaVpCi\nrxwzjTMO3+EDp3vl3UV89s9PrLLu4B02pG9lefPyouV1vL9oOVe3keQef30Omw7px9IVSclpXnVt\nppcyfW41jRFsNWzAaveLCOoagj4VZdw6/p12zztz0QoO/OOj3PHdvdlqWH8eeXUOmwzuy87DB2eK\nK2+qa5L3ddbiFYxOO5ec9PcJPPb6HKacexgV5Z3zXezZ6fP56Ij1OuVcHVXf0MjRVzzNKZ/alv22\nHdbh83zr+vEATP/t4Z0VWmZNVbFt3SN41OVjgY7FdsEDr3PJI1MY9/OD2GDdvh0PsguMnpiU+B+c\nNIu/jX2LGQuWc/UJH+3mqPKjJEtQp97+EgC19Y28OnMJ97z0Phc/PIUTr3uWRcvr2Obn93LevZMB\nePz1uasc27INY86SGmYs+GDV34UPvsE1T0xj4nvJt7yjLx/LoReOaTOmr18zjoP++Bhf+MuTH9j2\nq39P4h/Pz2j1uP3Pf5QD/7jqt9pFy+o+UB35pwff4ENn/odFy+uaXz/A+Omtd5Z4YPIsltU2cNhF\nY9juzPs46e8T+PwlSWx1DY25b8uJCOoLSshNSekPo19rXvfklOR3+82/jW9e99a86uZv5rX1jXzk\nrNHc9eJ71DU08nzae3J1jrxsbKfE3xELl9VS39DI/GW1THhrAV+7ehy3PPs2R172VLvHrqhraE7i\nkJQymjw5ZS5zl9assv/TU+d9YF1n2nLUvZx2x8rP6fS51czP+KWtPQ9OTj4Lc5d2zvnac+49k9r8\nYlropnFv85v0/86cJTUceuHjLE6/sDbdGtPZHbzqGhr52tXPMOGt9j/beVSSCWp1djnnfuobg8sf\nn8oL7yzkuqemr7J9y1H3MuL0e7jvlfeZsWAZHz33QS59dMoHznPZY2/yq7sncfjFT/DqzMW8OnNJ\nh2O65slp/OiWF3mtxTlaq56687kZ7PKr+9nrvIdXWX/Ls283v75CE95awIOTZjFu2nzemJXcX/WZ\ni8bwi3++0mosY9+cx7Zn/IdDLxzDbWlJ7E8PvM6zaaKbX13LqDtf5sDzH+3Qa12dV2cu5skpczn+\nmnGcevuLzUnyiTfmMnPRqlUfNzz9Ftuc8R+mza3mhXcWrva8j70+p/n5J//wKJ/98xP86t+TeG/h\ncpbW1PObeybzx/tf50t/fao5ef3m3slc/NAbNDTGB5J1bX0j8wr+eU94awEjTr+HcdPmM/bNeRx3\n1dMsqK5l1J0vrdLWuHBZLefeM+kDVc8n3/gcN4ydzk3j3mbhslpGnH4PV42Z2nyNiOC6J6ex668e\n4NQ7XqKsoNRx2h0v8+z0BXzvxucAmDa3mtlpNdGi5XU8//YClqyoY/tf3MeOZ43mPy+/z7ylNexY\nUA193FXPrJJ4q2vqOeaKp5tLMf98/l0OvfDxD7yv86trmzsX3fXie5x2+0tMem8xAG/MWsIjr7Xe\nWampjfjW8Su/lO1//qOrrV6csWAZ0+dWc8K141ZJtKvT3v2Qz06fz49ueYGI4PCLx/D7tHNSYxvT\nYE96bzHvzF/WvHz92OnMWVLDlWOm8b93T2o3nlF3vswVj09lxOn3cN69k1f5n1H4EXtpxsJWvyBG\nBIsy9PD9zb2TOfuuiYw4/R4ufPB1xrwxlyMve2qNqw+X1dazcFnXJPm2KE/flEeOHBnjx49vf8c2\njDj9nk6MJrv1+/fJXGVX6PVfH8Z5/5nMtU9Ob3ffD204gKEDqnjqzXnN6279zl5stl4/ZixYzvdu\nfI5Zi1f/jXdg3wqWrFizzhlbDe3P1LSd4uzP7cDZ/175h3jSJ7fmlE9tS9/Kcl6esYgh/SsZPmQd\nzr1nEvOW1nLB0bsCcPUT0ygTnLjPlrwxawkXPfQG6/fvQ2V5GT89ZLvmqtLWfn9PnHYA+/7uEYYO\n6MPYUQdRWV7GiroG9vv9I8xZsvrXK636h/+/X/zIKon5W/ttyZVjprHJoL5ss+FAHn99Dtee+FEO\n2G6D1X6WBlRVsLSmnjGnHsAG61Zx+WNTueCB1zlkxw2bS3IDqypYUlPP6Ydtz9f32oJ1+lTwo1te\n4B/Pv8tfj9udfbcdys5n39/mNQpj3mHjgXzl0vZLbg/++JPN/+Rf/OXBHH/tOF54ZyG7bDaYFwuS\n+I6brMvENJG05l8n79Nc0v/Rpz7U3Ib60tkHs6K2gXP+PYk/HLkzO/xyNNtvNJA9t1p/lS960397\nePP7V1hFV11Tz/K6hlXuz/v4lutx87f3ZMtR9zbvHxHNy2ce/mH2326DVZLXVsP68/BP9ue8eydT\nUS5+dsj2q8R/6IWP8+rMJfz+iJ3ZfqOB7Dx8MO/MX8b1Y6dz+4QZPP/Lg4GVn7dXzjmkud34ju/u\nzVcufYqhA6rYc6v1uOS/dgfgocmzmkvi0397ONPnVrP/+Y/y0RFDeHZ6Ujq59LjdOWynjdt8X1f3\nmfrT0bvwo1tepKJM1DcG53x+R3bdbDAPTJrFTw/ZDoCbx73N6Xe+zAM/+gRLauopk6gsFztuMijz\ndQp/H7MWr+Dul97nkB2T5oqhA6pW2Xev8x7i/UUrPlDNuqKugWOvfJo5S2p44rQD27xWVpImRMTI\nVrcVM0FJOhS4CCgHroqI365u/56aoDrqomN25Yc3v9Ap59pw3ap2E1RXaPoDW1N3fHevTP+Ehw7o\nU9Sqm903H8xzb6++RNZSy0TYmlu/sxffvyn5EjFsYFW7ybXQNhsM6NLedbedtFebVZlH7DGc2ye0\nXh3d5N/f25fPXZK02Y46bHv22WYox18zjnnVtc2Juy1nfW4HPrThQI676pnmdX88chd+ctuLq+x3\n9/f3bW4XnnLuYZSXJaVKSc0JqsnVx49cpZr38J025rv7b918/LNnfIqPnpskzYN32JD7J628Qf6M\nz3yYJTX1XJzewtK0//LaBhshMosAABBjSURBVD7xh0cYPqTfKk0Ad39/X56YMpfbxr/D776yM0dc\ntrItLUuCasuph27HA5Nm8fzbCxnUr5JFy1eWpCrLxXr9+zByi/W45+X32zxHUxyQlH53/98HVtn2\n5m8+A9D8XjbFO+bUA5i5eAXbbTSQIy59itdnLf3A+dZGtyQoSeXA68CngRnAs8CxEdFmWbi3JSgz\n635d/QWglLxx7mFUrmUHpNUlqGK2QX0MmBIRUyOiFrgZ+EIRr0ffynw1qe2/Xcd7WJlZ13By6rjD\nLmq7Y1hnKOZ/9E2Bwv7OM9J1RTPm1LWvD+1MV359ZLd04TUz6wpf2q2o/9K7/z4oSd8Gvg2w+eab\nr9W5hg2sYtp5n2H2khreW7ic8+59lb59yjlkxw1paAyuHDOV7x2wDf36VLBoWS0brtuXgz68YXOd\na2Nj8O7C5TwwaRaLV9RR3xCs178PtQ2NvDRjIYuX17PthgN4/u2kl81m663DvtsMpbK8jKenzmPx\nijr6VpZTVVHGzw7Zvrno25SkltbU8+6C5TRGUFEmpsxeyor6BsZNW0C/ynI+s9NG7Lb5EMrLxOIV\ndTwzdT6jJ87khXcWst+2Q6mqKGf0xJmMWH8ddt1sCPe8/B6vz1rKjpusy7c/sRW3PPsOJ31ya3bZ\nbDCD+lU2vy+LV9QxfW41b81bxpwlNcyvrmWdqnJO3HtL+vVZeS/X3KU19O9TwbzqGlbUNbJoeS0T\n31vMoTtuxLCBSQNqTX0j86prqSgTC5bVcu/LM/nEtkN5b9EKIoJ+leXUNwZ9K8vYaugAltbU8/TU\neey99VBem7WYrYcNoKExee8WVNfSp6KMedW1rNu3gvX7VzGoXyVlZWJ5bQNVFWU0pO/VnCU1rNe/\nDxXlZTQ2Bo0RlJeJiJWD8UoiIlhaU8+AqgqW1TY0v5eD+/Whpr6ByvIyKsvLWLKijgFVyce/TKKs\nbNX7cRoag7K0bakhgsryMiKCiKR33DpV5fQpL2NpTT39KsubP0M19Y3N+1aUlzF7yQo2GNi3uVdW\nY0CZkv2W1zZQUS76VJRRVVG+Ss+tptcSAbUNjVRVrPwuubSmnsrysubOJRHBwmV1rNuvkrqGRsok\npKQ9EGBJTT0D+lQ0v8aIoL5x5WtK1kEA9Y2NlEuUSdQ1JjHW1Deybt9K+laWMXdpLVWVZazbt5KI\nYPGKevqUl1FZrubfTUME9Q3B67OWsPPwQSyrbaBPRRl1DY30KS9jwbI61u/fByl5nyG5dnVNPf2r\nKlhR10BVRTllgory5LgFy2qpKi+nf1U51TUNqAz6lJcxa/EKNkzvdapvDJbXNrC8toENB1UhREXZ\nqr/buUtrqCgTfSvLKVOyvSmO+sbg7fnL2GbYAFbUN9CvspxFy+uoawgqy8XgdfpQW9/IouV19Kko\nY+qcpWw6pB8DqiqormkgIhjSvw/VNfVUVZSzZEUds5fUsP1GA6mubaC+oZH+VRVMen8xH9lkENU1\n9QQwqF8lDY1BTX0Dy+saKFfymUh+P7C8roF1+pTTt7KcxSvqKJeorW+ksqKMdSrLWbKinqrKsuRz\nrORm9bqG5HfW0BiUpe8VwIwFyykvE0MHVFFdU0/fynIkqKlr5J0Fyxg6oIoh/SvpU17GstoGGiIY\nWFXBgmV1NKafx2EDq9q9j62zFLMNai/g7Ig4JF0eBRAR57V1zNq2QZmZWc/SXW1QzwLbStpSUh/g\nGOCuIl7PzMxKSNGq+CKiXtL3gNEk3cyviYiJxbqemZmVlqK2QUXEvcC9xbyGmZmVpnz1yzYzM0s5\nQZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS45QZmZWS7lakZdSXOAt7o7jtUYCszt\n7iA6qKfG7ri7Xk+N3XF3vc6IfYuIaHVuolwlqLyTNL6tQQ3zrqfG7ri7Xk+N3XF3vWLH7io+MzPL\nJScoMzPLJSeoNXNFdwewFnpq7I676/XU2B131ytq7G6DMjOzXHIJyszMcskJyszMcqlXJyhJfSWN\nk/SipImSzknXbynpGUlTJN2STlmPpKp0eUq6fUTBuUal61+TdEgXxV8u6XlJd/ewuKdLelnSC5LG\np+vWk/SApDfSn0PS9ZJ0cRrjS5J2LzjP8en+b0g6vgviHizpdkmvSposaa8eEvd26Xvd9Fgs6ZQe\nEvuP0r/NVyTdlP7N5v5zLumHacwTJZ2Srsvl+y3pGkmzJb1SsK7TYpW0R/r3PiU9VpmDi4he+wAE\nDEifVwLPAHsCtwLHpOsvA76bPv8f4LL0+THALenzHYAXgSpgS+BNoLwL4v8xcCNwd7rcU+KeDgxt\nse73wOnp89OB36XPPwP8J/1d7Qk8k65fD5ia/hySPh9S5Lj/Bvx3+rwPMLgnxN3iNZQDM4Et8h47\nsCkwDehX8Pk+Ie+fc+AjwCvAOiSzlj8IbJPX9xv4BLA78ErBuk6LFRiX7qv02MMyx9ZVfxh5f6Qf\npueAj5PcGV2Rrt8LGJ0+Hw3slT6vSPcTMAoYVXCu5v2KGO9w4CHgQODuNI7cx51eZzofTFCvARun\nzzcGXkufXw4c23I/4Fjg8oL1q+xXhJgHkfyzVE+Ku5XXcTDwZE+InSRBvZP+06tIP+eH5P1zDhwJ\nXF2w/Avg1Dy/38AIVk1QnRJruu3VgvWr7Nfeo1dX8UFzNdkLwGzgAZJvVwsjoj7dZQbJHwqs/IMh\n3b4IWL9wfSvHFMuFJB/6xnR5fXpG3AAB3C9pgqRvp+s2jIj30+czgQ3T523F2NWxbwnMAa5VUq16\nlaT+PSDulo4Bbkqf5zr2iHgXOB94G3if5HM7gfx/zl8B9pO0vqR1SEodm5Hz97uFzop10/R5y/WZ\n9PoEFRENEbErSYnkY8D23RxSuyR9FpgdERO6O5YO2jcidgcOA06W9InCjZF81crb/Q8VJNUgl0bE\nbkA1SdVHs5zG3Sxtq/k8cFvLbXmMPW33+ALJl4NNgP7Aod0aVAYRMRn4HXA/cB/wAtDQYp/cvd9t\n6c5Ye32CahIRC4FHSKoMBkuqSDcNB95Nn79L8k2IdPsgYF7h+laOKYZ9gM9Lmg7cTFLNd1EPiBto\n/mZMRMwG/kHyxWCWpI3TGDcmKdGuEnuLGLs69hnAjIh4Jl2+nSRh5T3uQocBz0XErHQ577F/CpgW\nEXMiog64k+Szn/vPeURcHRF7RMQngAXA6+T//S7UWbG+mz5vuT6TXp2gJA2TNDh93g/4NDCZJFEd\nke52PPCv9Pld6TLp9ofTbxd3AcekvYi2BLYlaRgsiogYFRHDI2IESZXNwxFxXN7jBpDUX9LApuck\nbSKvtIixZexfT3sP7QksSqseRgMHSxqSftM+OF1XFBExE3hH0nbpqoOASXmPu4VjWVm91xRjnmN/\nG9hT0jppz6+m97wnfM43SH9uDnyZpDNT3t/vQp0Sa7ptsaQ909/h1wvO1b5iNRT2hAewM/A88BLJ\nP8lfpuu3IvkATyGpDqlK1/dNl6ek27cqONcZJO1Xr7EGvVQ64TXsz8pefLmPO43xxfQxETgjXb8+\nSaePN0h6Pa2XrhfwlzTGl4GRBef6RvqapgAndkHsuwLj08/LP0l6K+U+7vSa/UlKE4MK1uU+duAc\n4NX07/MGkp54PeFzPoYkmb4IHJTn95vkS8v7QB1JTcE3OzNWYGT6+3sTuIQWHY1W9/BQR2Zmlku9\nuorPzMzyywnKzMxyyQnKzMxyyQnKzMxyyQnKzMxyyQnKOp2kBq06evbp7ex/kqSvd8J1p0saurbn\naecaZ0v6aRHOe4KkOQXv2fWSPt/03kn6oqQdWuy/ScHyVYXbS5mkESoYedtKV0X7u5itseWRDB+V\nSURcVsxgepBbIuJ7Ldbdlf78IslgqZPS5RNI7i15DyAi/rsrAuxMkipi5Zh6H1g2cwnKukxawvl9\nOjfMOEnbpOubSyWSfiBpkpK5Zm5O160n6Z/puqcl7ZyuX1/S/Urm3LmK5CbCpmt9Nb3GC5IuVzIo\ncLmk65TM0/OypB+1iK9c0rT0LvnBaUnwE+m2xyVtm+66g6RHJU2V9IPVXTNdv1TSuUrmHXta0oZk\nkJaSLpG0N8kYen9Iz30ayc2P/5cu90vjGbm660naOl1+WdKvJS1t47o/Tt+jV5TOZZSu/3r6O3hR\n0g3pug0l/SNd96KkvVuWcCT9VNLZ6fNHJV2oZB6wH7ayvIekx5QMJDxaK4fb2aPpGsDJWd4/6/mc\noKwY+mnVKr6jC7YtioidSO4ov7CVY08HdouInYGT0nXnAM+n634OXJ+uPwt4IiJ2JBnTb3MASR8G\njgb2SUtyDcBxJCNBbBoRH0ljuLbwwhHRQDLSwA7AviTTr+wnqQrYLCLeSHfdnmTah48BZ0mqXM01\nIRnF4emI2AV4HPhWG+/b0QXv2YkFcT1FUpL6WUTsGhG/IxnR4rh0eXmL87R1vYuAi9LXPoNWSNoD\nOJFk2pk9gW9J2k3SjsCZwIHpeX+YHnIx8Fi6bneS0UHa0yciRkbEHwuX03P9GTgiIvYArgHOTfe5\nFvh+eh3rJVzFZ8Wwuiq+mwp+/qmV7S+RlAz+STKcECTJ4isAEfFwWnJal2SitS+n6++RtCDd/yBg\nD+BZJZN39iMZ7PLfwFaS/gzcQzLadEtj0vNuCZxH8s/9MeDZgn3uiYgaoEbSbJKpCNq6JkAtSfUc\nJNNFfLqN92aVKj5JJ7SxX3vaut5eJFWFkIwNd34rx+4L/CMiqtMY7gT2IxnN+raImAsQEfPT/Q8k\nGV+tKcEvUjr76mrc0sbydiST/T2QvoflwPtKxsscHBGPp/vdQDLwrZU4JyjratHG8yaHkySIzwFn\nSNqpA9cQ8LeIGPWBDdIuJKWfk4CjSMYPK/Q48F2S6R1+CfyMZLzDMQX71BQ8byD5O2rzmkBdrBxT\nrGn/Yurq67VUz6q1M31bbK9uY1nAxIjYq3BjmqCsF3IVn3W1owt+ji3cIKmMpCrtEeA0kukSBpAk\nh+PSffYH5kbEYpJk8l/p+sNIBm+FZJDLI7RyROn1JG2hpIdfWUTcQVJdtXsr8Y0D9gYaI2IFyVw+\n30mvtTqtXrP9tyOzJcDA1Sxn8TRpSZRkFPzWjAG+qGQE8f7Al9J1DwNHSlofkteX7v8QSUJvasMb\nBMwCNkhLulXAZzPG9xowTNJe6fkqJe0YyVQ4CyXtm+53XJtnsJLiEpQVQz8lsxQ3uS8imrqaD5H0\nEkkp5NgWx5UDf0//yQm4OCIWpg3s16THLWPlNADnADdJmgg8RTI9AxExSdKZJLP2lpGM0nwysJxk\nRtymL2YfKO1ERI2kd0j+mUPyz/lYkpGb27Saa761uuPWwM3AlWmnjCOA64DLJC0nqbrL4hSS9/cM\nkon0FrXcISKek3QdK6ejuCoingeQdC7wmKQGklkATiBpi7pC0jdJSmvfjYixkn6VnuNdktHI2xUR\ntZKOAC5OPwMVJO2UE0naxa6RFLReNWslyKOZW5dRMsHiyKZ2DOtaSqYfXx4RIekY4NiI+EJ3x2XW\nFpegzHqPPYBLlPRAWMgH29/McsUlKDMzyyV3kjAzs1xygjIzs1xygjIzs1xygjIzs1xygjIzs1z6\nf3b2CFK3vGVSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO_dvpdAuUUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "1bcca617-c622-4496-a5f1-2e96cec545fa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAFgCAYAAADuCe0ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBPP9JtCuVEF",
        "colab_type": "text"
      },
      "source": [
        "#### Analysis on performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AN92fSru0F0",
        "colab_type": "text"
      },
      "source": [
        "**Method:** I implemented a Deep Q Network (DQN) to solve this problem. The only input to these networks are the agents’ independent states, along with the timestep. I used an individual ANN for each network, which was routinely fitted by random sampling from an experience replay. This was done at regular intervals, instead of after each action, in an attempt to keep the data i.i.d. Before fitting begins, the agents are allowed to explore the environment randomly, in order to adequately fill the replay memory. This stops the agents taking the first plausible strategy and getting stop in a local minimum.\n",
        "Effectiveness/Results: The results can be seen in the Learning Curve, the two Loss Graphs and the Testing Phase.\n",
        "\n",
        "Testing: Even though it is not explicitly requested, the system was tested by just drawing actions from the networks (no exploration) and visualising the system. The system does not **always** work, due to randomness(and other defects described here), although it **often** works and the Learning Curve shows that it does learn adequately.\n",
        "\n",
        "**Analysis:** The system works well – it achieves a solution which satisfies the reward criteria in an effective manner, taking advantage of the timestep information provided to the networks in a manner such that one agent waits for the other to complete the course before they start their action. The optimal minimum number of steps to complete is 13, and this system regularly gets close to this optimum. This is verified by the visual video, along with the graphs provided.\n",
        "\n",
        "The Learning Curve is intriguing, my method of training plateaus the system at a relatively high epsilon, so that it can learn not to get stuck in local minima. This, along with the relative disparate of the system (due to the lack of a target network perhaps) means that the reward seems to oscillate between episodes, although the maximum reward increases, showing that learning is occurring. Target Networks, full grid-searching hyperparameter optimisation, target frequency optimisation and the like would remove this uncertainty/oscillation within the system. Even when the system fails, visualising the movement shows that the two agents are just out of time with one another and get stuck in the corridor, meaning that they have already learned their own strategies (they are not moving randomly) but have badly estimated the timestep aspect. This shows that each agent is learning well.\n",
        "\n",
        "The loss function graphs offer good insight into the inner workings of the system. The small oscillation on the loss graph is as expected, since the policy is constantly changing. If the loss graphs were to show spikes, this could be indicative of exploding gradients, which can imply that the agent has hit a local optimum/results that are unexpected and hence the policy has changed dramatically (ie when the agent gets stuck in the corridor). Gradient Clipping can often remedy this. The lack of spikes in my loss graphs shows that they each conform to a global minimum and optimal policy well.\n",
        "\n",
        "**Words: 493**\n",
        "\n",
        "**Sources (Note only papers are fully cited, as BibTex referencing for websites is unavailable in notebooks):**\n",
        "\n",
        "Mnih, V., Kavukcuoglu, K., Silver, D. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015). https://doi.org/10.1038/nature14236\n",
        "\n",
        "https://keras.io/callbacks/ (For Loss History Class)\n",
        "\n",
        "https://medium.com/@jonathan_hui/rl-dqn-deep-q-network-e207751f7ae4\n",
        "\n",
        "https://pythonprogramming.net/training-deep-q-learning-dqn-reinforcement-learning-python-tutorial/?completed=/deep-q-learning-dqn-reinforcement-learning-python-tutorial/\n",
        "\n",
        "https://towardsdatascience.com/dqn-part-1-vanilla-deep-q-networks-6eb4a00febfb\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/\n",
        "\n"
      ]
    }
  ]
}